{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "f2575392019334285e0602a4035eec46b9260ee4c95297ea34ade6e3c8b8fcaf"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "MIA Shokri.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUL709HhYt6p"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYPugKKhYt6r"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers import MaxPooling2D, Add\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten, UpSampling2D, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn import model_selection,tree\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1-PUnQIYt6s"
      },
      "source": [
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45PZTvVlYt6t"
      },
      "source": [
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "#for RESNET\n",
        "\n",
        "\n",
        "# def model():\n",
        "# \tbase_model = ResNet50(include_top=False, input_shape=(128, 128, 3), pooling='max')\n",
        "\t\n",
        "# \tfor layer in base_model.layers:\n",
        "# \t\tlayer.trainable = False\n",
        "# \tmodel = Sequential()\n",
        "# \tmodel.add(Conv2DTranspose(3, (3, 3), strides=2, padding='same', activation='relu', input_shape=(32,32,3)))\n",
        "# \tmodel.add(BatchNormalization())\n",
        "# \tmodel.add(Conv2DTranspose(3, (3, 3), strides=2, padding='same', activation='relu'))\n",
        "# \tmodel.add(BatchNormalization())\n",
        "# \tmodel.add(base_model)\n",
        "# \tmodel.add(Flatten())\n",
        "# \tmodel.add(Dense(1024, activation='relu'))\n",
        "# \tmodel.add(Dense(512, activation='relu'))\n",
        "# \tmodel.add(Dense(10, activation='softmax'))\n",
        " \n",
        "#   # opt = SGD(lr=0.001, momentum=0.9)\n",
        "\n",
        "#   model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\t\n",
        "\t# return model\n",
        "\n",
        "def resnet():\n",
        "    visible = Input(shape=(32,32,3))\n",
        "# first feature extractor\n",
        "    conv1 = Conv2D(64, kernel_size=4, activation='relu',padding='same')(visible)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv1)\n",
        "    bn1 = BatchNormalization()(pool1)\n",
        "    print(bn1.shape)\n",
        "    conv2 = Conv2D(64, kernel_size=4, activation='relu',padding='same')(conv1)\n",
        "    conv3 = Conv2D(64, kernel_size=4, activation='relu',padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv3)\n",
        "    bn2 = BatchNormalization()(pool2)\n",
        "    # print(bn2.shape)\n",
        "    # conv3 = Conv2D(32, kernel_size=4, activation='relu',padding='same')(bn2)\n",
        "    # pool3 = MaxPooling2D(pool_size=(2, 2),padding='same')(conv3)\n",
        "    # bn3 = BatchNormalization()(pool3)\n",
        "    # print(bn3.shape)\n",
        "\n",
        "\n",
        "\n",
        "    add1 = Add()([bn1, bn2])\n",
        "\n",
        "    # conv4 = Conv2D(128, kernel_size=4, activation='relu')(add1)\n",
        "    # pool4 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv4)\n",
        "    # bn4 = BatchNormalization()(pool4)\n",
        "\n",
        "    # conv5 = Conv2D(128, kernel_size=4, activation='relu')(bn4)\n",
        "    # pool5 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv5)\n",
        "    # bn5 = BatchNormalization()(pool5)\n",
        "\n",
        "\n",
        "    flat1 = Flatten()(add1)\n",
        "    # second feature extractor\n",
        "    # conv2 = Conv2D(32, kernel_size=8, activation='relu',padding='same')(visible)\n",
        "    # pool2 = MaxPooling2D(pool_size=(2, 2), ,padding='same')(conv2)\n",
        "    # flat2 = Flatten()(pool2)\n",
        "    # merge feature extractors\n",
        "    # merge = Add()([pool1, pool2])\n",
        "    # # interpretation layer\n",
        "    hidden1 = Dense(128, activation='relu')(flat1)\n",
        "    # prediction output\n",
        "    output = Dense(10, activation='softmax')(hidden1)\n",
        "    model = Model(inputs=visible, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "    \n",
        "    # summarize layers\n",
        "    # print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjvry5l2Yt6u",
        "outputId": "2a6f3e10-5fa6-457e-9380-8dbd152a96c5"
      },
      "source": [
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "def preprocess_image_input(input_images):\n",
        "\tinput_images = input_images.astype('float32')\n",
        "\toutput_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "\treturn output_ims\n",
        "\n",
        "\n",
        "    \n",
        "shadow_models = 3\n",
        "models = []\n",
        "hist = []\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_dataset()\n",
        "# x_train = preprocess_image_input(x_train)\n",
        "# x_test = preprocess_image_input(x_test)\n",
        "x_train, x_test = prep_pixels(x_train, x_test)\n",
        "train_x = []\n",
        "train_y = []\n",
        "for i in range(x_train.shape[0] + x_test.shape[0]):\n",
        "\t\n",
        "\tif i<x_train.shape[0]:\n",
        "\t\ttrain_x.append(x_train[i])\n",
        "\t\ttrain_y.append(y_train[i])\n",
        "\telse:\n",
        "\t\ttrain_x.append(x_test[i-50000])\n",
        "\t\ttrain_y.append(y_test[i-50000])\n",
        "\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 32, 32, 3)\n",
            "(60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gvOCnIsYt6v"
      },
      "source": [
        "# shadow_models = 2\n",
        "# models = []\n",
        "# hist = []\n",
        "\n",
        "# x_train, y_train, x_test, y_test = load_dataset()\n",
        "# # x_train = preprocess_image_input(x_train)\n",
        "# # x_test = preprocess_image_input(x_test)\n",
        "# x_train, x_test = prep_pixels(x_train, x_test)\n",
        "\n",
        "attack_x = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for i in range(shadow_models):\n",
        "#     x_data_i = train_x[((i) * 40000) : min(x_train.shape[0], (i+1)*40000)]\n",
        "#     y_data_i = train_y[((i) * 40000) : min(y_train.shape[0], (i+1)*40000)]\n",
        "#     # datagen = ImageDataGenerator(\n",
        "#     # featurewise_center=True,\n",
        "#     # featurewise_std_normalization=True,\n",
        "#     # rotation_range=20,\n",
        "#     # width_shift_range=0.2,\n",
        "#     # height_shift_range=0.2,\n",
        "#     # horizontal_flip=True,\n",
        "#     # validation_split=0.2)\n",
        "#     x_train_i, x_test_i, y_train_i, y_test_i = model_selection.train_test_split(x_data_i, y_data_i, random_state=17, train_size=0.5)\n",
        "#     # datagen.fit(x_train_i)\n",
        "\n",
        "#     model_i = define_model()\n",
        "#     if i==0:\n",
        "#         print(model_i.summary())\n",
        "#     epochs = 10\n",
        "#     print(\"Training model: \" + str(i+1) + \" for data from \" + str(i * 40000 ) + \" to \" + str( min(y_train.shape[0], (i+1)*40000)))\n",
        "#     # hist_i = model_i.fit(datagen.flow(x_train_i, y_train_i, batch_size=16),epochs=epochs, validation_data=(x_test_i, y_test_i), batch_size=64, verbose=True)\n",
        "    \n",
        "#     hist_i = model_i.fit(x_train_i, y_train_i, epochs=200, batch_size=64, verbose=True, validation_data=(x_test_i, y_test_i))\n",
        "#     models.append(model_i)\n",
        "#     hist.append(hist_i)\n",
        "#     preds_test = model_i.predict(x_test_i)\n",
        "#     preds_train = model_i.predict(x_train_i)\n",
        "\n",
        "#     for j in range(len(x_train_i)):\n",
        "#         temp = []\n",
        "#         for k in range(len(preds_train[j])):\n",
        "#             temp.append(preds_train[j][k])\n",
        "        \n",
        "#         temp.append(np.argmax(y_train_i[j]))\n",
        "#         temp.append(1)\n",
        "#         attack_x.append(temp)\n",
        "        \n",
        "    \n",
        "#     for j in range(len(x_test_i)):\n",
        "#         temp = []\n",
        "#         for k in range(len(preds_test[j])):\n",
        "#             temp.append(preds_test[j][k])\n",
        "        \n",
        "#         temp.append(np.argmax(y_test_i[j]))\n",
        "#         temp.append(0)\n",
        "#         attack_x.append(temp)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq98EPs0Yt6w",
        "outputId": "2a67bb01-3bdd-4371-d293-c5d6d488d5d5"
      },
      "source": [
        "for i in range(shadow_models):\n",
        "  data_init = i * 10000\n",
        "  data_final = data_init + 40000\n",
        "  data_x_i = train_x[data_init : data_final]\n",
        "  data_y_i = train_y[data_init : data_final]\n",
        "  model_i = define_model()\n",
        "  if i==0:\n",
        "      print(model_i.summary())\n",
        "  epochs = 10\n",
        "  print(\"Training model: \" + str(i+1) + \" for data from \" + str(data_init ) + \" to \" + str( data_final))\n",
        "  x_train_i, x_test_i, y_train_i, y_test_i = model_selection.train_test_split(data_x_i, data_y_i, random_state=17, train_size=0.5)\n",
        "  hist_i = model_i.fit(x_train_i,y_train_i, epochs=100, verbose=True, validation_data=(x_test_i, y_test_i))\n",
        "  models.append(model_i)\n",
        "  hist.append(hist_i)\n",
        "  preds_test = model_i.predict(x_test_i)\n",
        "  preds_train = model_i.predict(x_train_i)\n",
        "\n",
        "  for j in range(len(x_train_i)):\n",
        "      temp = []\n",
        "      for k in range(len(preds_train[j])):\n",
        "          temp.append(preds_train[j][k])\n",
        "      \n",
        "      temp.append(np.argmax(y_train_i[j]))\n",
        "      temp.append(1)\n",
        "      attack_x.append(temp)\n",
        "      \n",
        "\n",
        "  for j in range(len(x_test_i)):\n",
        "      temp = []\n",
        "      for k in range(len(preds_test[j])):\n",
        "          temp.append(preds_test[j][k])\n",
        "      \n",
        "      temp.append(np.argmax(y_test_i[j]))\n",
        "      temp.append(0)\n",
        "      attack_x.append(temp)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               262272    \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 550,570\n",
            "Trainable params: 550,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model: 1 for data from 0 to 40000\n",
            "Epoch 1/100\n",
            "625/625 [==============================] - 18s 27ms/step - loss: 2.2064 - accuracy: 0.1659 - val_loss: 1.9933 - val_accuracy: 0.3016\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 1.9033 - accuracy: 0.2939 - val_loss: 1.7274 - val_accuracy: 0.3704\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.7559 - accuracy: 0.3517 - val_loss: 1.6059 - val_accuracy: 0.4130\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 1.6533 - accuracy: 0.3900 - val_loss: 1.5277 - val_accuracy: 0.4374\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.5841 - accuracy: 0.4177 - val_loss: 1.4910 - val_accuracy: 0.4572\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.5190 - accuracy: 0.4381 - val_loss: 1.4309 - val_accuracy: 0.4735\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.4802 - accuracy: 0.4587 - val_loss: 1.3713 - val_accuracy: 0.5008\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.4358 - accuracy: 0.4773 - val_loss: 1.3257 - val_accuracy: 0.5199\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.3782 - accuracy: 0.4985 - val_loss: 1.2751 - val_accuracy: 0.5371\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 1.3470 - accuracy: 0.5124 - val_loss: 1.2205 - val_accuracy: 0.5568\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.3058 - accuracy: 0.5314 - val_loss: 1.1881 - val_accuracy: 0.5678\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.2707 - accuracy: 0.5372 - val_loss: 1.2228 - val_accuracy: 0.5577\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 1.2471 - accuracy: 0.5515 - val_loss: 1.1441 - val_accuracy: 0.5845\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 1.2019 - accuracy: 0.5651 - val_loss: 1.1848 - val_accuracy: 0.5659\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.1815 - accuracy: 0.5734 - val_loss: 1.0793 - val_accuracy: 0.6104\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 1.1484 - accuracy: 0.5875 - val_loss: 1.0614 - val_accuracy: 0.6166\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 1.1221 - accuracy: 0.5989 - val_loss: 1.0579 - val_accuracy: 0.6202\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.0878 - accuracy: 0.6091 - val_loss: 1.0856 - val_accuracy: 0.6183\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.0637 - accuracy: 0.6204 - val_loss: 1.0184 - val_accuracy: 0.6387\n",
            "Epoch 20/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 1.0428 - accuracy: 0.6279 - val_loss: 0.9915 - val_accuracy: 0.6471\n",
            "Epoch 21/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 1.0206 - accuracy: 0.6348 - val_loss: 0.9598 - val_accuracy: 0.6554\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9966 - accuracy: 0.6406 - val_loss: 0.9231 - val_accuracy: 0.6687\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.9716 - accuracy: 0.6515 - val_loss: 0.9202 - val_accuracy: 0.6748\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.9504 - accuracy: 0.6602 - val_loss: 0.8964 - val_accuracy: 0.6787\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.9334 - accuracy: 0.6665 - val_loss: 0.9216 - val_accuracy: 0.6681\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.9155 - accuracy: 0.6722 - val_loss: 0.8919 - val_accuracy: 0.6805\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.8950 - accuracy: 0.6794 - val_loss: 0.9036 - val_accuracy: 0.6762\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8837 - accuracy: 0.6863 - val_loss: 0.9001 - val_accuracy: 0.6772\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.8666 - accuracy: 0.6973 - val_loss: 0.8624 - val_accuracy: 0.6928\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.8466 - accuracy: 0.7033 - val_loss: 0.8568 - val_accuracy: 0.6990\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.8341 - accuracy: 0.7017 - val_loss: 0.8301 - val_accuracy: 0.7036\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.8188 - accuracy: 0.7143 - val_loss: 0.8214 - val_accuracy: 0.7097\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.8033 - accuracy: 0.7182 - val_loss: 0.8068 - val_accuracy: 0.7126\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.7945 - accuracy: 0.7225 - val_loss: 0.8068 - val_accuracy: 0.7143\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.7751 - accuracy: 0.7283 - val_loss: 0.7881 - val_accuracy: 0.7198\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.7657 - accuracy: 0.7269 - val_loss: 0.7972 - val_accuracy: 0.7192\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.7435 - accuracy: 0.7357 - val_loss: 0.7841 - val_accuracy: 0.7276\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.7373 - accuracy: 0.7379 - val_loss: 0.7747 - val_accuracy: 0.7282\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.7287 - accuracy: 0.7401 - val_loss: 0.8171 - val_accuracy: 0.7158\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.7071 - accuracy: 0.7480 - val_loss: 0.7831 - val_accuracy: 0.7256\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.7048 - accuracy: 0.7515 - val_loss: 0.7808 - val_accuracy: 0.7301\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.6956 - accuracy: 0.7539 - val_loss: 0.7549 - val_accuracy: 0.7382\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.6860 - accuracy: 0.7538 - val_loss: 0.7513 - val_accuracy: 0.7369\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.6690 - accuracy: 0.7621 - val_loss: 0.7352 - val_accuracy: 0.7437\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.6589 - accuracy: 0.7618 - val_loss: 0.7649 - val_accuracy: 0.7336\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.6558 - accuracy: 0.7675 - val_loss: 0.7516 - val_accuracy: 0.7363\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.6385 - accuracy: 0.7728 - val_loss: 0.7401 - val_accuracy: 0.7436\n",
            "Epoch 48/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.6320 - accuracy: 0.7738 - val_loss: 0.7349 - val_accuracy: 0.7481\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.6211 - accuracy: 0.7796 - val_loss: 0.7332 - val_accuracy: 0.7501\n",
            "Epoch 50/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.6166 - accuracy: 0.7812 - val_loss: 0.7273 - val_accuracy: 0.7485\n",
            "Epoch 51/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.5964 - accuracy: 0.7867 - val_loss: 0.7409 - val_accuracy: 0.7518\n",
            "Epoch 52/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.5851 - accuracy: 0.7904 - val_loss: 0.7052 - val_accuracy: 0.7544\n",
            "Epoch 53/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.5841 - accuracy: 0.7895 - val_loss: 0.7342 - val_accuracy: 0.7498\n",
            "Epoch 54/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.5781 - accuracy: 0.7939 - val_loss: 0.7148 - val_accuracy: 0.7575\n",
            "Epoch 55/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.5728 - accuracy: 0.7971 - val_loss: 0.7278 - val_accuracy: 0.7524\n",
            "Epoch 56/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.5536 - accuracy: 0.8022 - val_loss: 0.7084 - val_accuracy: 0.7565\n",
            "Epoch 57/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.5494 - accuracy: 0.8030 - val_loss: 0.7229 - val_accuracy: 0.7532\n",
            "Epoch 58/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.5424 - accuracy: 0.8033 - val_loss: 0.7070 - val_accuracy: 0.7592\n",
            "Epoch 59/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.5360 - accuracy: 0.8105 - val_loss: 0.7088 - val_accuracy: 0.7574\n",
            "Epoch 60/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.5170 - accuracy: 0.8139 - val_loss: 0.7160 - val_accuracy: 0.7599\n",
            "Epoch 61/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.5170 - accuracy: 0.8146 - val_loss: 0.7236 - val_accuracy: 0.7581\n",
            "Epoch 62/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.5103 - accuracy: 0.8180 - val_loss: 0.6966 - val_accuracy: 0.7656\n",
            "Epoch 63/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.4954 - accuracy: 0.8218 - val_loss: 0.7054 - val_accuracy: 0.7653\n",
            "Epoch 64/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.4901 - accuracy: 0.8245 - val_loss: 0.7153 - val_accuracy: 0.7612\n",
            "Epoch 65/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.4814 - accuracy: 0.8288 - val_loss: 0.7146 - val_accuracy: 0.7643\n",
            "Epoch 66/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.4821 - accuracy: 0.8267 - val_loss: 0.7231 - val_accuracy: 0.7617\n",
            "Epoch 67/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4700 - accuracy: 0.8327 - val_loss: 0.7126 - val_accuracy: 0.7637\n",
            "Epoch 68/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.4650 - accuracy: 0.8338 - val_loss: 0.6983 - val_accuracy: 0.7671\n",
            "Epoch 69/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.4532 - accuracy: 0.8367 - val_loss: 0.7032 - val_accuracy: 0.7699\n",
            "Epoch 70/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.4539 - accuracy: 0.8342 - val_loss: 0.7275 - val_accuracy: 0.7648\n",
            "Epoch 71/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.4405 - accuracy: 0.8420 - val_loss: 0.7376 - val_accuracy: 0.7650\n",
            "Epoch 72/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.4379 - accuracy: 0.8411 - val_loss: 0.7037 - val_accuracy: 0.7714\n",
            "Epoch 73/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.4328 - accuracy: 0.8460 - val_loss: 0.7566 - val_accuracy: 0.7660\n",
            "Epoch 74/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4198 - accuracy: 0.8510 - val_loss: 0.7245 - val_accuracy: 0.7639\n",
            "Epoch 75/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.4237 - accuracy: 0.8486 - val_loss: 0.7265 - val_accuracy: 0.7677\n",
            "Epoch 76/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4141 - accuracy: 0.8492 - val_loss: 0.7337 - val_accuracy: 0.7703\n",
            "Epoch 77/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4059 - accuracy: 0.8561 - val_loss: 0.7125 - val_accuracy: 0.7710\n",
            "Epoch 78/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3953 - accuracy: 0.8565 - val_loss: 0.7096 - val_accuracy: 0.7756\n",
            "Epoch 79/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3927 - accuracy: 0.8585 - val_loss: 0.7300 - val_accuracy: 0.7704\n",
            "Epoch 80/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3957 - accuracy: 0.8546 - val_loss: 0.7344 - val_accuracy: 0.7696\n",
            "Epoch 81/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3778 - accuracy: 0.8675 - val_loss: 0.7511 - val_accuracy: 0.7702\n",
            "Epoch 82/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.3702 - accuracy: 0.8657 - val_loss: 0.7305 - val_accuracy: 0.7739\n",
            "Epoch 83/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3729 - accuracy: 0.8638 - val_loss: 0.7457 - val_accuracy: 0.7684\n",
            "Epoch 84/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3744 - accuracy: 0.8632 - val_loss: 0.7093 - val_accuracy: 0.7764\n",
            "Epoch 85/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3650 - accuracy: 0.8672 - val_loss: 0.7387 - val_accuracy: 0.7753\n",
            "Epoch 86/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3501 - accuracy: 0.8729 - val_loss: 0.7481 - val_accuracy: 0.7728\n",
            "Epoch 87/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3523 - accuracy: 0.8759 - val_loss: 0.7383 - val_accuracy: 0.7748\n",
            "Epoch 88/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3460 - accuracy: 0.8766 - val_loss: 0.7247 - val_accuracy: 0.7759\n",
            "Epoch 89/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3405 - accuracy: 0.8784 - val_loss: 0.7309 - val_accuracy: 0.7749\n",
            "Epoch 90/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3344 - accuracy: 0.8791 - val_loss: 0.7561 - val_accuracy: 0.7736\n",
            "Epoch 91/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3320 - accuracy: 0.8793 - val_loss: 0.7675 - val_accuracy: 0.7750\n",
            "Epoch 92/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3252 - accuracy: 0.8824 - val_loss: 0.7364 - val_accuracy: 0.7784\n",
            "Epoch 93/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3312 - accuracy: 0.8807 - val_loss: 0.7302 - val_accuracy: 0.7804\n",
            "Epoch 94/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3177 - accuracy: 0.8848 - val_loss: 0.7361 - val_accuracy: 0.7815\n",
            "Epoch 95/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3227 - accuracy: 0.8832 - val_loss: 0.7260 - val_accuracy: 0.7811\n",
            "Epoch 96/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3137 - accuracy: 0.8883 - val_loss: 0.7279 - val_accuracy: 0.7807\n",
            "Epoch 97/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3097 - accuracy: 0.8896 - val_loss: 0.7769 - val_accuracy: 0.7774\n",
            "Epoch 98/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.3042 - accuracy: 0.8903 - val_loss: 0.7528 - val_accuracy: 0.7812\n",
            "Epoch 99/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3026 - accuracy: 0.8892 - val_loss: 0.7326 - val_accuracy: 0.7839\n",
            "Epoch 100/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.3027 - accuracy: 0.8896 - val_loss: 0.7478 - val_accuracy: 0.7779\n",
            "Training model: 2 for data from 10000 to 50000\n",
            "Epoch 1/100\n",
            "625/625 [==============================] - 17s 25ms/step - loss: 2.1852 - accuracy: 0.1805 - val_loss: 1.9951 - val_accuracy: 0.2777\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 1.9435 - accuracy: 0.2776 - val_loss: 1.7333 - val_accuracy: 0.3728\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 1.7704 - accuracy: 0.3460 - val_loss: 1.6231 - val_accuracy: 0.4130\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.6512 - accuracy: 0.3909 - val_loss: 1.5371 - val_accuracy: 0.4438\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 1.5637 - accuracy: 0.4187 - val_loss: 1.4891 - val_accuracy: 0.4489\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 1.5024 - accuracy: 0.4465 - val_loss: 1.3925 - val_accuracy: 0.4999\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 1.4490 - accuracy: 0.4710 - val_loss: 1.3406 - val_accuracy: 0.5149\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 1.4014 - accuracy: 0.4847 - val_loss: 1.3389 - val_accuracy: 0.5209\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.3494 - accuracy: 0.5060 - val_loss: 1.2613 - val_accuracy: 0.5375\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.3114 - accuracy: 0.5229 - val_loss: 1.2388 - val_accuracy: 0.5518\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.2793 - accuracy: 0.5383 - val_loss: 1.1561 - val_accuracy: 0.5900\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.2353 - accuracy: 0.5537 - val_loss: 1.1544 - val_accuracy: 0.5815\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 1.2106 - accuracy: 0.5696 - val_loss: 1.1158 - val_accuracy: 0.6022\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.1700 - accuracy: 0.5767 - val_loss: 1.0609 - val_accuracy: 0.6260\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 1.1365 - accuracy: 0.5925 - val_loss: 1.0511 - val_accuracy: 0.6271\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 1.1078 - accuracy: 0.6033 - val_loss: 1.0171 - val_accuracy: 0.6427\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.0762 - accuracy: 0.6118 - val_loss: 1.0536 - val_accuracy: 0.6293\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 1.0492 - accuracy: 0.6263 - val_loss: 0.9512 - val_accuracy: 0.6592\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.0292 - accuracy: 0.6303 - val_loss: 0.9434 - val_accuracy: 0.6658\n",
            "Epoch 20/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.0022 - accuracy: 0.6428 - val_loss: 0.9400 - val_accuracy: 0.6669\n",
            "Epoch 21/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.9729 - accuracy: 0.6551 - val_loss: 0.8964 - val_accuracy: 0.6804\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.9556 - accuracy: 0.6604 - val_loss: 0.8885 - val_accuracy: 0.6873\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.9358 - accuracy: 0.6675 - val_loss: 0.8782 - val_accuracy: 0.6873\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.9190 - accuracy: 0.6763 - val_loss: 0.8660 - val_accuracy: 0.6914\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.8878 - accuracy: 0.6891 - val_loss: 0.9183 - val_accuracy: 0.6782\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.8836 - accuracy: 0.6880 - val_loss: 0.8464 - val_accuracy: 0.7017\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.8605 - accuracy: 0.6925 - val_loss: 0.8188 - val_accuracy: 0.7108\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.8375 - accuracy: 0.6984 - val_loss: 0.8113 - val_accuracy: 0.7146\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.8345 - accuracy: 0.7050 - val_loss: 0.8036 - val_accuracy: 0.7154\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.8162 - accuracy: 0.7136 - val_loss: 0.8148 - val_accuracy: 0.7165\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.8011 - accuracy: 0.7174 - val_loss: 0.7818 - val_accuracy: 0.7236\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.7763 - accuracy: 0.7251 - val_loss: 0.7912 - val_accuracy: 0.7225\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.7655 - accuracy: 0.7281 - val_loss: 0.7778 - val_accuracy: 0.7279\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.7581 - accuracy: 0.7295 - val_loss: 0.7775 - val_accuracy: 0.7248\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.7471 - accuracy: 0.7361 - val_loss: 0.7679 - val_accuracy: 0.7322\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.7329 - accuracy: 0.7409 - val_loss: 0.7507 - val_accuracy: 0.7386\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.7205 - accuracy: 0.7437 - val_loss: 0.7546 - val_accuracy: 0.7357\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - 17s 26ms/step - loss: 0.7141 - accuracy: 0.7486 - val_loss: 0.7300 - val_accuracy: 0.7432\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.6944 - accuracy: 0.7501 - val_loss: 0.7596 - val_accuracy: 0.7355\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.6815 - accuracy: 0.7605 - val_loss: 0.7445 - val_accuracy: 0.7422\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.6773 - accuracy: 0.7589 - val_loss: 0.7271 - val_accuracy: 0.7465\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.6726 - accuracy: 0.7609 - val_loss: 0.7165 - val_accuracy: 0.7499\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.6517 - accuracy: 0.7700 - val_loss: 0.7439 - val_accuracy: 0.7427\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.6462 - accuracy: 0.7702 - val_loss: 0.7150 - val_accuracy: 0.7552\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.6368 - accuracy: 0.7745 - val_loss: 0.7181 - val_accuracy: 0.7506\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.6239 - accuracy: 0.7783 - val_loss: 0.7335 - val_accuracy: 0.7492\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.6124 - accuracy: 0.7810 - val_loss: 0.7293 - val_accuracy: 0.7519\n",
            "Epoch 48/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.6025 - accuracy: 0.7861 - val_loss: 0.7120 - val_accuracy: 0.7551\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.5884 - accuracy: 0.7890 - val_loss: 0.7590 - val_accuracy: 0.7426\n",
            "Epoch 50/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.5840 - accuracy: 0.7898 - val_loss: 0.6858 - val_accuracy: 0.7655\n",
            "Epoch 51/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.5714 - accuracy: 0.7940 - val_loss: 0.6863 - val_accuracy: 0.7674\n",
            "Epoch 52/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.5661 - accuracy: 0.8011 - val_loss: 0.7043 - val_accuracy: 0.7617\n",
            "Epoch 53/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.5635 - accuracy: 0.7979 - val_loss: 0.7009 - val_accuracy: 0.7650\n",
            "Epoch 54/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.5524 - accuracy: 0.8037 - val_loss: 0.7065 - val_accuracy: 0.7640\n",
            "Epoch 55/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.5373 - accuracy: 0.8055 - val_loss: 0.6806 - val_accuracy: 0.7659\n",
            "Epoch 56/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.5338 - accuracy: 0.8128 - val_loss: 0.6750 - val_accuracy: 0.7705\n",
            "Epoch 57/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.5246 - accuracy: 0.8135 - val_loss: 0.6999 - val_accuracy: 0.7617\n",
            "Epoch 58/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.5212 - accuracy: 0.8138 - val_loss: 0.7052 - val_accuracy: 0.7643\n",
            "Epoch 59/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.5073 - accuracy: 0.8171 - val_loss: 0.6834 - val_accuracy: 0.7719\n",
            "Epoch 60/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.5042 - accuracy: 0.8195 - val_loss: 0.7107 - val_accuracy: 0.7667\n",
            "Epoch 61/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.4915 - accuracy: 0.8248 - val_loss: 0.6817 - val_accuracy: 0.7699\n",
            "Epoch 62/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.4918 - accuracy: 0.8260 - val_loss: 0.6870 - val_accuracy: 0.7738\n",
            "Epoch 63/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.4883 - accuracy: 0.8250 - val_loss: 0.6703 - val_accuracy: 0.7770\n",
            "Epoch 64/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4715 - accuracy: 0.8299 - val_loss: 0.6742 - val_accuracy: 0.7760\n",
            "Epoch 65/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.4609 - accuracy: 0.8338 - val_loss: 0.6596 - val_accuracy: 0.7807\n",
            "Epoch 66/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.4604 - accuracy: 0.8339 - val_loss: 0.6816 - val_accuracy: 0.7741\n",
            "Epoch 67/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.4488 - accuracy: 0.8375 - val_loss: 0.6797 - val_accuracy: 0.7795\n",
            "Epoch 68/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.4473 - accuracy: 0.8385 - val_loss: 0.6941 - val_accuracy: 0.7718\n",
            "Epoch 69/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.4364 - accuracy: 0.8432 - val_loss: 0.6708 - val_accuracy: 0.7818\n",
            "Epoch 70/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.4330 - accuracy: 0.8425 - val_loss: 0.6702 - val_accuracy: 0.7846\n",
            "Epoch 71/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4311 - accuracy: 0.8469 - val_loss: 0.6845 - val_accuracy: 0.7771\n",
            "Epoch 72/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.4251 - accuracy: 0.8439 - val_loss: 0.7009 - val_accuracy: 0.7788\n",
            "Epoch 73/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4089 - accuracy: 0.8514 - val_loss: 0.6990 - val_accuracy: 0.7779\n",
            "Epoch 74/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.4019 - accuracy: 0.8525 - val_loss: 0.6738 - val_accuracy: 0.7815\n",
            "Epoch 75/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.4052 - accuracy: 0.8545 - val_loss: 0.7011 - val_accuracy: 0.7819\n",
            "Epoch 76/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3929 - accuracy: 0.8594 - val_loss: 0.6753 - val_accuracy: 0.7844\n",
            "Epoch 77/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3921 - accuracy: 0.8553 - val_loss: 0.6985 - val_accuracy: 0.7836\n",
            "Epoch 78/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3833 - accuracy: 0.8612 - val_loss: 0.6783 - val_accuracy: 0.7815\n",
            "Epoch 79/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3883 - accuracy: 0.8585 - val_loss: 0.6650 - val_accuracy: 0.7872\n",
            "Epoch 80/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3794 - accuracy: 0.8661 - val_loss: 0.6738 - val_accuracy: 0.7876\n",
            "Epoch 81/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3716 - accuracy: 0.8652 - val_loss: 0.7196 - val_accuracy: 0.7778\n",
            "Epoch 82/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.3619 - accuracy: 0.8686 - val_loss: 0.6887 - val_accuracy: 0.7833\n",
            "Epoch 83/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3517 - accuracy: 0.8716 - val_loss: 0.7124 - val_accuracy: 0.7805\n",
            "Epoch 84/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3576 - accuracy: 0.8708 - val_loss: 0.7491 - val_accuracy: 0.7750\n",
            "Epoch 85/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3543 - accuracy: 0.8723 - val_loss: 0.6957 - val_accuracy: 0.7839\n",
            "Epoch 86/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3358 - accuracy: 0.8781 - val_loss: 0.6906 - val_accuracy: 0.7871\n",
            "Epoch 87/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3431 - accuracy: 0.8756 - val_loss: 0.7397 - val_accuracy: 0.7772\n",
            "Epoch 88/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.3363 - accuracy: 0.8806 - val_loss: 0.7037 - val_accuracy: 0.7887\n",
            "Epoch 89/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3256 - accuracy: 0.8823 - val_loss: 0.6995 - val_accuracy: 0.7868\n",
            "Epoch 90/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3296 - accuracy: 0.8791 - val_loss: 0.7012 - val_accuracy: 0.7877\n",
            "Epoch 91/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.3225 - accuracy: 0.8814 - val_loss: 0.7159 - val_accuracy: 0.7843\n",
            "Epoch 92/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3125 - accuracy: 0.8874 - val_loss: 0.6966 - val_accuracy: 0.7886\n",
            "Epoch 93/100\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.3141 - accuracy: 0.8877 - val_loss: 0.7152 - val_accuracy: 0.7864\n",
            "Epoch 94/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3095 - accuracy: 0.8878 - val_loss: 0.7214 - val_accuracy: 0.7891\n",
            "Epoch 95/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3103 - accuracy: 0.8882 - val_loss: 0.7099 - val_accuracy: 0.7872\n",
            "Epoch 96/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3023 - accuracy: 0.8888 - val_loss: 0.7305 - val_accuracy: 0.7893\n",
            "Epoch 97/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.2972 - accuracy: 0.8910 - val_loss: 0.7310 - val_accuracy: 0.7860\n",
            "Epoch 98/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.2943 - accuracy: 0.8928 - val_loss: 0.7310 - val_accuracy: 0.7873\n",
            "Epoch 99/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.2946 - accuracy: 0.8939 - val_loss: 0.7251 - val_accuracy: 0.7898\n",
            "Epoch 100/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.2820 - accuracy: 0.8982 - val_loss: 0.7392 - val_accuracy: 0.7883\n",
            "Training model: 3 for data from 20000 to 60000\n",
            "Epoch 1/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 2.2028 - accuracy: 0.1767 - val_loss: 2.0284 - val_accuracy: 0.2578\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.9936 - accuracy: 0.2582 - val_loss: 1.8898 - val_accuracy: 0.2968\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 1.8089 - accuracy: 0.3185 - val_loss: 1.6344 - val_accuracy: 0.3954\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.6771 - accuracy: 0.3737 - val_loss: 1.5382 - val_accuracy: 0.4431\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 1.5857 - accuracy: 0.4160 - val_loss: 1.4574 - val_accuracy: 0.4651\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 1.5154 - accuracy: 0.4463 - val_loss: 1.3827 - val_accuracy: 0.4956\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 1.4602 - accuracy: 0.4708 - val_loss: 1.3404 - val_accuracy: 0.5271\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 1.4063 - accuracy: 0.4854 - val_loss: 1.2778 - val_accuracy: 0.5351\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 1.3659 - accuracy: 0.5018 - val_loss: 1.2455 - val_accuracy: 0.5527\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 1.3148 - accuracy: 0.5260 - val_loss: 1.1945 - val_accuracy: 0.5688\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 1.2835 - accuracy: 0.5339 - val_loss: 1.2381 - val_accuracy: 0.5577\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 1.2331 - accuracy: 0.5548 - val_loss: 1.1199 - val_accuracy: 0.5982\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 1.2038 - accuracy: 0.5623 - val_loss: 1.1020 - val_accuracy: 0.6007\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 1.1674 - accuracy: 0.5803 - val_loss: 1.1220 - val_accuracy: 0.5918\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 1.1400 - accuracy: 0.5897 - val_loss: 1.0765 - val_accuracy: 0.6148\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 1.1178 - accuracy: 0.6000 - val_loss: 0.9991 - val_accuracy: 0.6404\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 1.0999 - accuracy: 0.6093 - val_loss: 1.0004 - val_accuracy: 0.6397\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 1.0631 - accuracy: 0.6173 - val_loss: 0.9734 - val_accuracy: 0.6554\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 1.0405 - accuracy: 0.6311 - val_loss: 1.0242 - val_accuracy: 0.6366\n",
            "Epoch 20/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 1.0172 - accuracy: 0.6366 - val_loss: 0.9237 - val_accuracy: 0.6704\n",
            "Epoch 21/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 1.0012 - accuracy: 0.6404 - val_loss: 0.9307 - val_accuracy: 0.6654\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.9754 - accuracy: 0.6515 - val_loss: 0.9166 - val_accuracy: 0.6725\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.9530 - accuracy: 0.6597 - val_loss: 0.8759 - val_accuracy: 0.6855\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.9382 - accuracy: 0.6662 - val_loss: 0.8730 - val_accuracy: 0.6859\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.9225 - accuracy: 0.6728 - val_loss: 0.9406 - val_accuracy: 0.6616\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.8991 - accuracy: 0.6789 - val_loss: 0.8323 - val_accuracy: 0.6993\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.8835 - accuracy: 0.6902 - val_loss: 0.8896 - val_accuracy: 0.6837\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.8749 - accuracy: 0.6873 - val_loss: 0.8466 - val_accuracy: 0.7007\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.8554 - accuracy: 0.6974 - val_loss: 0.8406 - val_accuracy: 0.6972\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.8433 - accuracy: 0.7020 - val_loss: 0.8009 - val_accuracy: 0.7142\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.8327 - accuracy: 0.7031 - val_loss: 0.8453 - val_accuracy: 0.7010\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.8064 - accuracy: 0.7123 - val_loss: 0.7843 - val_accuracy: 0.7220\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.7997 - accuracy: 0.7161 - val_loss: 0.7761 - val_accuracy: 0.7251\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.7814 - accuracy: 0.7211 - val_loss: 0.7693 - val_accuracy: 0.7287\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.7688 - accuracy: 0.7286 - val_loss: 0.7553 - val_accuracy: 0.7327\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.7534 - accuracy: 0.7351 - val_loss: 0.7882 - val_accuracy: 0.7197\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.7482 - accuracy: 0.7323 - val_loss: 0.7484 - val_accuracy: 0.7380\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.7370 - accuracy: 0.7383 - val_loss: 0.7534 - val_accuracy: 0.7352\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.7120 - accuracy: 0.7462 - val_loss: 0.7658 - val_accuracy: 0.7291\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - 18s 30ms/step - loss: 0.7126 - accuracy: 0.7472 - val_loss: 0.7295 - val_accuracy: 0.7424\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.6946 - accuracy: 0.7514 - val_loss: 0.7242 - val_accuracy: 0.7495\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.6914 - accuracy: 0.7589 - val_loss: 0.7440 - val_accuracy: 0.7390\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.6837 - accuracy: 0.7592 - val_loss: 0.7237 - val_accuracy: 0.7467\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.6625 - accuracy: 0.7650 - val_loss: 0.7185 - val_accuracy: 0.7510\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.6551 - accuracy: 0.7661 - val_loss: 0.7117 - val_accuracy: 0.7545\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.6433 - accuracy: 0.7713 - val_loss: 0.7209 - val_accuracy: 0.7514\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.6303 - accuracy: 0.7756 - val_loss: 0.7173 - val_accuracy: 0.7509\n",
            "Epoch 48/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.6324 - accuracy: 0.7750 - val_loss: 0.6953 - val_accuracy: 0.7575\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.6208 - accuracy: 0.7808 - val_loss: 0.6942 - val_accuracy: 0.7587\n",
            "Epoch 50/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.6079 - accuracy: 0.7845 - val_loss: 0.7182 - val_accuracy: 0.7524\n",
            "Epoch 51/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.6072 - accuracy: 0.7830 - val_loss: 0.7097 - val_accuracy: 0.7555\n",
            "Epoch 52/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.5852 - accuracy: 0.7919 - val_loss: 0.6864 - val_accuracy: 0.7653\n",
            "Epoch 53/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.5864 - accuracy: 0.7893 - val_loss: 0.7320 - val_accuracy: 0.7494\n",
            "Epoch 54/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.5754 - accuracy: 0.7947 - val_loss: 0.7057 - val_accuracy: 0.7551\n",
            "Epoch 55/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.5631 - accuracy: 0.8000 - val_loss: 0.7116 - val_accuracy: 0.7584\n",
            "Epoch 56/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.5556 - accuracy: 0.8022 - val_loss: 0.6607 - val_accuracy: 0.7704\n",
            "Epoch 57/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.5536 - accuracy: 0.8019 - val_loss: 0.6866 - val_accuracy: 0.7678\n",
            "Epoch 58/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.5362 - accuracy: 0.8102 - val_loss: 0.6639 - val_accuracy: 0.7729\n",
            "Epoch 59/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.5350 - accuracy: 0.8084 - val_loss: 0.6650 - val_accuracy: 0.7747\n",
            "Epoch 60/100\n",
            "625/625 [==============================] - 18s 30ms/step - loss: 0.5165 - accuracy: 0.8142 - val_loss: 0.6930 - val_accuracy: 0.7650\n",
            "Epoch 61/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.5181 - accuracy: 0.8163 - val_loss: 0.7043 - val_accuracy: 0.7643\n",
            "Epoch 62/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.5089 - accuracy: 0.8191 - val_loss: 0.6614 - val_accuracy: 0.7748\n",
            "Epoch 63/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.4995 - accuracy: 0.8205 - val_loss: 0.6616 - val_accuracy: 0.7807\n",
            "Epoch 64/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.4932 - accuracy: 0.8272 - val_loss: 0.6610 - val_accuracy: 0.7779\n",
            "Epoch 65/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.4848 - accuracy: 0.8290 - val_loss: 0.6817 - val_accuracy: 0.7741\n",
            "Epoch 66/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.4822 - accuracy: 0.8264 - val_loss: 0.6691 - val_accuracy: 0.7765\n",
            "Epoch 67/100\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 0.4720 - accuracy: 0.8310 - val_loss: 0.6718 - val_accuracy: 0.7750\n",
            "Epoch 68/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.4611 - accuracy: 0.8308 - val_loss: 0.6749 - val_accuracy: 0.7777\n",
            "Epoch 69/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.4630 - accuracy: 0.8336 - val_loss: 0.6652 - val_accuracy: 0.7800\n",
            "Epoch 70/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.4545 - accuracy: 0.8354 - val_loss: 0.6816 - val_accuracy: 0.7778\n",
            "Epoch 71/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.4469 - accuracy: 0.8421 - val_loss: 0.6679 - val_accuracy: 0.7828\n",
            "Epoch 72/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.4462 - accuracy: 0.8371 - val_loss: 0.6734 - val_accuracy: 0.7784\n",
            "Epoch 73/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.4198 - accuracy: 0.8504 - val_loss: 0.6796 - val_accuracy: 0.7770\n",
            "Epoch 74/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.4266 - accuracy: 0.8449 - val_loss: 0.6775 - val_accuracy: 0.7812\n",
            "Epoch 75/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.4224 - accuracy: 0.8476 - val_loss: 0.6665 - val_accuracy: 0.7826\n",
            "Epoch 76/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.4159 - accuracy: 0.8481 - val_loss: 0.6951 - val_accuracy: 0.7779\n",
            "Epoch 77/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.4099 - accuracy: 0.8532 - val_loss: 0.6736 - val_accuracy: 0.7851\n",
            "Epoch 78/100\n",
            "625/625 [==============================] - 15s 25ms/step - loss: 0.3984 - accuracy: 0.8591 - val_loss: 0.6881 - val_accuracy: 0.7843\n",
            "Epoch 79/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.4006 - accuracy: 0.8545 - val_loss: 0.6700 - val_accuracy: 0.7832\n",
            "Epoch 80/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.3904 - accuracy: 0.8608 - val_loss: 0.6684 - val_accuracy: 0.7825\n",
            "Epoch 81/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.3863 - accuracy: 0.8610 - val_loss: 0.6571 - val_accuracy: 0.7857\n",
            "Epoch 82/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.3835 - accuracy: 0.8615 - val_loss: 0.6743 - val_accuracy: 0.7868\n",
            "Epoch 83/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.3700 - accuracy: 0.8666 - val_loss: 0.6993 - val_accuracy: 0.7786\n",
            "Epoch 84/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.3593 - accuracy: 0.8699 - val_loss: 0.6854 - val_accuracy: 0.7825\n",
            "Epoch 85/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3621 - accuracy: 0.8693 - val_loss: 0.7006 - val_accuracy: 0.7854\n",
            "Epoch 86/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3588 - accuracy: 0.8712 - val_loss: 0.6764 - val_accuracy: 0.7857\n",
            "Epoch 87/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3600 - accuracy: 0.8701 - val_loss: 0.6746 - val_accuracy: 0.7843\n",
            "Epoch 88/100\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 0.3548 - accuracy: 0.8706 - val_loss: 0.6852 - val_accuracy: 0.7889\n",
            "Epoch 89/100\n",
            "625/625 [==============================] - 19s 30ms/step - loss: 0.3488 - accuracy: 0.8766 - val_loss: 0.6986 - val_accuracy: 0.7843\n",
            "Epoch 90/100\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 0.3287 - accuracy: 0.8827 - val_loss: 0.6902 - val_accuracy: 0.7910\n",
            "Epoch 91/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.3297 - accuracy: 0.8821 - val_loss: 0.6993 - val_accuracy: 0.7852\n",
            "Epoch 92/100\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 0.3321 - accuracy: 0.8802 - val_loss: 0.7135 - val_accuracy: 0.7828\n",
            "Epoch 93/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.3247 - accuracy: 0.8816 - val_loss: 0.7032 - val_accuracy: 0.7867\n",
            "Epoch 94/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.3260 - accuracy: 0.8824 - val_loss: 0.6862 - val_accuracy: 0.7893\n",
            "Epoch 95/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.3198 - accuracy: 0.8870 - val_loss: 0.6942 - val_accuracy: 0.7894\n",
            "Epoch 96/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3198 - accuracy: 0.8852 - val_loss: 0.6980 - val_accuracy: 0.7897\n",
            "Epoch 97/100\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3067 - accuracy: 0.8883 - val_loss: 0.7285 - val_accuracy: 0.7874\n",
            "Epoch 98/100\n",
            "625/625 [==============================] - 18s 28ms/step - loss: 0.3073 - accuracy: 0.8900 - val_loss: 0.7038 - val_accuracy: 0.7879\n",
            "Epoch 99/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.3031 - accuracy: 0.8885 - val_loss: 0.7115 - val_accuracy: 0.7910\n",
            "Epoch 100/100\n",
            "625/625 [==============================] - 18s 29ms/step - loss: 0.2936 - accuracy: 0.8925 - val_loss: 0.7352 - val_accuracy: 0.7872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxY-2exHYt6x"
      },
      "source": [
        "attack_x = np.array(attack_x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e06c5SPbYt6x"
      },
      "source": [
        "attack_models_no = 10\n",
        "attack_models = []\n",
        "score = []\n",
        "for i in range(attack_models_no):\n",
        "    attack_model_i = tree.DecisionTreeClassifier()\n",
        "    data_i = attack_x[attack_x[:, -2] == i]\n",
        "    data_x_i = data_i[:, 0:-1]\n",
        "    data_y_i = data_i[:, -1]\n",
        "    data_train_x_i, data_test_x_i, data_train_y_i, data_test_y_i = model_selection.train_test_split(data_x_i, data_y_i,train_size=0.3,random_state=17)\n",
        "    attack_model_i.fit(data_train_x_i, data_train_y_i)\n",
        "    score.append(attack_model_i.score(data_test_x_i, data_test_y_i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX82cAtbYt6y",
        "outputId": "0a488b2d-334e-49c9-f491-e8758c6f9919"
      },
      "source": [
        "np.average(score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.568205311447284"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VSqjH9sYt6z"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3WtCxM5Yt6z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljegq0BqYt6z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsvidnQ-Yt60"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58-qoQutYt60"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}